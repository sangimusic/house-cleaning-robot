{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "46JjgZXDtvvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1200aa2f-ee7b-4d46-a655-8f42fa17932f"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5/releases/tag/v7.0  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 2.3.0+cu121 (Tesla T4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQaDPCKQuRMH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQanvpjXuUiT",
        "outputId": "a53daead-c54b-4712-dbbd-2d901d4bdb3c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdu6_xN6vVP_",
        "outputId": "ffd95300-e300-4ef5-9d45-627cb5b51354"
      },
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/yolov5/last.pt --img 640 --conf 0.25 --source ../image1038.jpg --save-txt\n",
        "#Image(filename='runs/detect/exp/zidane.jpg', width=600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/yolov5/last.pt'], source=../image1038.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 üöÄ v7.0-333-gb9019671 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 224 layers, 7062001 parameters, 0 gradients\n",
            "WARNING ‚ö†Ô∏è NMS time limit 0.550s exceeded\n",
            "image 1/1 /content/image1038.jpg: 640x384 3 Furnitures, 62.6ms\n",
            "Speed: 0.5ms pre-process, 62.6ms inference, 719.8ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n",
            "1 labels saved to runs/detect/exp2/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgcjjczPqg1f",
        "outputId": "05c56b6a-a722-4438-e91c-468bb417d009"
      },
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/last.pt --img 640 --conf 0.25 --source ../image1038.jpg --save-txt\n",
        "#Image(filename='runs/detect/exp/zidane.jpg', width=600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/last.pt'], source=../image1038.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 üöÄ v7.0-333-gb9019671 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 224 layers, 7062001 parameters, 0 gradients\n",
            "WARNING ‚ö†Ô∏è NMS time limit 0.550s exceeded\n",
            "image 1/1 /content/image1038.jpg: 640x384 3 Furnitures, 51.2ms\n",
            "Speed: 0.4ms pre-process, 51.2ms inference, 916.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n",
            "1 labels saved to runs/detect/exp3/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5tZkAQXyTN9"
      },
      "source": [
        "!unzip -q ../train_data.zip -d ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGqNV5FhyZmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccaa793a-a72c-498e-d1be-151e1461679a",
        "collapsed": true
      },
      "source": [
        "# Testing\n",
        "!python val.py --weights runs/train/exp/weights/last.pt --data custom_data.yaml --img 640 --iou 0.65"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/custom_data.yaml, weights=['runs/train/exp/weights/last.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 üöÄ v7.0-333-gb9019671 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/val.py\", line 438, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/val.py\", line 409, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5/val.py\", line 165, in run\n",
            "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
            "  File \"/content/yolov5/models/common.py\", line 467, in __init__\n",
            "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
            "  File \"/content/yolov5/models/experimental.py\", line 98, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location=\"cpu\")  # load\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1004, in load\n",
            "    with _open_zipfile_reader(opened_file) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 456, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileReader(name_or_buffer))\n",
            "RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfEEC4GAyiOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e75fbd-9585-4fed-e29a-52862d44a961"
      },
      "source": [
        "# Train YOLOv5s on custom_weights.pt for 3 epochs\n",
        "!python train.py --img 640 --batch 2 --epochs 20 --data custom_data.yaml --weights yolov5s.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-06-30 17:51:37.683325: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-30 17:51:37.683375: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-30 17:51:37.684750: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=custom_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=2, imgsz=640, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "YOLOv5 üöÄ v7.0-333-gb9019671 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train_data/labels/train.cache... 302 images, 26 backgrounds, 0 corrupt: 100% 304/304 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.2GB ram): 100% 304/304 [00:07<00:00, 42.78it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/train_data/labels/val.cache... 62 images, 2 backgrounds, 0 corrupt: 100% 62/62 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 62/62 [00:01<00:00, 50.46it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.81 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to runs/train/exp4/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp4\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/19     0.709G     0.0933    0.03836    0.04257         11        640: 100% 152/152 [00:19<00:00,  7.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:01<00:00,  9.35it/s]\n",
            "                   all         62        138     0.0052      0.691     0.0183    0.00517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/19     0.709G    0.06967    0.04053    0.03877          7        640: 100% 152/152 [00:14<00:00, 10.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:01<00:00, 13.46it/s]\n",
            "                   all         62        138      0.522      0.104     0.0704     0.0222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/19     0.709G     0.0609    0.03716    0.03489         10        640: 100% 152/152 [00:14<00:00, 10.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 18.82it/s]\n",
            "                   all         62        138      0.166      0.158     0.0962     0.0375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/19     0.709G    0.05763    0.03827    0.03355          9        640: 100% 152/152 [00:15<00:00, 10.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 18.94it/s]\n",
            "                   all         62        138      0.254      0.228      0.208      0.106\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/19     0.709G    0.05446    0.03548    0.03288          5        640: 100% 152/152 [00:14<00:00, 10.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 19.11it/s]\n",
            "                   all         62        138      0.364       0.28      0.216     0.0924\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/19     0.709G    0.05259    0.03207    0.03189          6        640: 100% 152/152 [00:15<00:00,  9.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 19.87it/s]\n",
            "                   all         62        138      0.302      0.265      0.211      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/19     0.709G    0.04896    0.03233    0.03053          4        640: 100% 152/152 [00:14<00:00, 10.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 19.68it/s]\n",
            "                   all         62        138      0.309      0.356      0.309      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/19     0.709G    0.04351    0.03206    0.02918         10        640: 100% 152/152 [00:14<00:00, 10.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 18.51it/s]\n",
            "                   all         62        138      0.254      0.375      0.291      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/19     0.709G    0.04344    0.03037    0.02844         11        640: 100% 152/152 [00:14<00:00, 10.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:01<00:00, 13.26it/s]\n",
            "                   all         62        138      0.303        0.4      0.329      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/19     0.709G    0.04268    0.03044    0.02778         10        640: 100% 152/152 [00:13<00:00, 11.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:01<00:00, 13.00it/s]\n",
            "                   all         62        138      0.329      0.426       0.39      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/19     0.709G     0.0395    0.03047    0.02663         10        640: 100% 152/152 [00:14<00:00, 10.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 16.82it/s]\n",
            "                   all         62        138      0.385      0.414      0.381        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/19     0.709G    0.03936    0.02987    0.02605          9        640: 100% 152/152 [00:14<00:00, 10.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 19.62it/s]\n",
            "                   all         62        138      0.332      0.524       0.43      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/19     0.709G     0.0371    0.03052    0.02535          8        640: 100% 152/152 [00:14<00:00, 10.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 19.41it/s]\n",
            "                   all         62        138      0.354      0.552      0.444      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/19     0.709G    0.03805    0.02852    0.02428         10        640: 100% 152/152 [00:15<00:00, 10.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 19.68it/s]\n",
            "                   all         62        138      0.422      0.526      0.511      0.237\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/19     0.709G    0.03457    0.02726    0.02311          5        640: 100% 152/152 [00:15<00:00,  9.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 19.12it/s]\n",
            "                   all         62        138      0.522      0.457      0.517      0.241\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/19     0.709G    0.03417    0.02777    0.02274          9        640: 100% 152/152 [00:15<00:00,  9.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 19.32it/s]\n",
            "                   all         62        138      0.727      0.379       0.55      0.287\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/19     0.709G    0.03334    0.02819    0.02218          5        640: 100% 152/152 [00:13<00:00, 10.91it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:01<00:00, 13.06it/s]\n",
            "                   all         62        138      0.615      0.457      0.567        0.3\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/19     0.709G    0.03109    0.02664    0.02159          9        640: 100% 152/152 [00:13<00:00, 11.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:01<00:00, 13.46it/s]\n",
            "                   all         62        138      0.613      0.457      0.573       0.28\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/19     0.709G    0.03131    0.02764     0.0213         10        640: 100% 152/152 [00:15<00:00, 10.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 18.98it/s]\n",
            "                   all         62        138      0.622      0.448      0.583      0.285\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/19     0.709G    0.03088      0.026    0.01982          9        640: 100% 152/152 [00:14<00:00, 10.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:00<00:00, 19.53it/s]\n",
            "                   all         62        138      0.554      0.492      0.573      0.306\n",
            "\n",
            "20 epochs completed in 0.088 hours.\n",
            "Optimizer stripped from runs/train/exp4/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp4/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp4/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:01<00:00, 15.36it/s]\n",
            "                   all         62        138      0.555      0.492      0.572      0.305\n",
            "         small_garment         62         18       0.46      0.389       0.42      0.151\n",
            "                 Doors         62         23      0.502      0.609      0.676      0.321\n",
            "             Furniture         62         41      0.546      0.293      0.441      0.279\n",
            "                 Cable         62         56       0.71      0.679       0.75      0.471\n",
            "Results saved to \u001b[1mruns/train/exp4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SicQHF1HyZlM"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4Y4SbcZuBcr"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}